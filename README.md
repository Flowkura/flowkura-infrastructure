# ğŸš€ Flowkura Infrastructure - RAGFlow Production

Infrastructure complÃ¨te pour dÃ©ployer RAGFlow en production avec SGLang, Ollama et Traefik.

## ğŸ“‹ Table des matiÃ¨res

- [Architecture](#architecture)
- [PrÃ©requis](#prÃ©requis)
- [Installation rapide](#installation-rapide)
- [Configuration](#configuration)
- [Services](#services)
- [ModÃ¨les utilisÃ©s](#modÃ¨les-utilisÃ©s)
- [Commandes utiles](#commandes-utiles)
- [Troubleshooting](#troubleshooting)
- [Optimisations](#optimisations)

---

## ğŸ—ï¸ Architecture

\`\`\`
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           Internet (HTTPS)                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚      Traefik Reverse Proxy (443/80)        â”‚
â”‚    SSL via Let's Encrypt                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           RAGFlow Server                    â”‚
â”‚       (ragflow.flowkura.com)                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â”‚           â”‚           â”‚
â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â” â”Œâ”€â–¼â”€â”€â”€â”€â”€â” â”Œâ”€â”€â–¼â”€â”€â”€â”€â”€â”
â”‚  SGLang     â”‚ â”‚Ollama â”‚ â”‚ MySQL  â”‚
â”‚  Qwen3-8B   â”‚ â”‚bge-m3 â”‚ â”‚ Redis  â”‚
â”‚  (Chat LLM) â”‚ â”‚(Embed)â”‚ â”‚ ES     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜
\`\`\`

---

## âš™ï¸ PrÃ©requis

### MatÃ©riel
- **GPU NVIDIA** (minimum 24GB VRAM recommandÃ© pour Qwen3-8B)
- **RAM** : 32GB minimum
- **Stockage** : 100GB minimum

### Logiciels
- Ubuntu 22.04 LTS
- Docker 24.0+
- Docker Compose V2
- NVIDIA Docker Runtime
- Git

---

## ğŸš€ Installation rapide

### 1. Clone du repository

\`\`\`bash
cd /root
git clone https://github.com/Flowkura/infrastructure.git flowkura-infrastructure
cd flowkura-infrastructure/ragflow/docker
\`\`\`

### 2. Configuration de l'environnement

\`\`\`bash
# Le fichier .env est dÃ©jÃ  configurÃ©
# Modifier les variables si nÃ©cessaire
nano .env
\`\`\`

**Variables importantes :**
\`\`\`bash
# Domaine
RAGFLOW_DOMAIN=ragflow.flowkura.com

# Email pour Let's Encrypt
ACME_EMAIL=contact.lenne@gmail.com

# DÃ©sactiver l'inscription
ENABLE_REGISTER=false

# Mot de passe MySQL/Redis
MYSQL_PASSWORD=infini_rag_flow
REDIS_PASSWORD=infini_rag_flow
\`\`\`

### 3. TÃ©lÃ©chargement des modÃ¨les

**Sur le serveur :**

\`\`\`bash
# 1. Lancer Ollama temporairement
docker run -d --name ollama-temp \\
  --gpus all \\
  -v ~/.ollama:/root/.ollama \\
  ollama/ollama:latest

# 2. TÃ©lÃ©charger bge-m3 (embedding)
docker exec ollama-temp ollama pull bge-m3

# 3. ArrÃªter et supprimer le container temporaire
docker stop ollama-temp && docker rm ollama-temp
\`\`\`

### 4. Lancement de l'infrastructure

\`\`\`bash
cd /root/flowkura-infrastructure/ragflow/docker

# Lancer tous les services
docker compose -f docker-compose-gpu.yml up -d

# VÃ©rifier que tout est UP
docker compose -f docker-compose-gpu.yml ps
\`\`\`

### 5. Configuration initiale RAGFlow

AccÃ©der Ã  : \`https://ragflow.flowkura.com\`

1. **Se connecter** avec les credentials existants
2. **Les modÃ¨les sont dÃ©jÃ  configurÃ©s** :
   - **SGLang/Qwen3-8B** : Chat LLM
   - **Ollama/bge-m3** : Embedding

3. **Les datasets sont prÃªts** :
   - Fiches MÃ©tiers ONISEP
   - Fiches Formations ONISEP

---

## ğŸ”§ Configuration

### Fichiers principaux

\`\`\`
ragflow/
â”œâ”€â”€ docker/
â”‚   â”œâ”€â”€ docker-compose-gpu.yml    # Compose principal GPU
â”‚   â”œâ”€â”€ docker-compose-base.yml   # Services de base
â”‚   â”œâ”€â”€ .env                      # Variables d'environnement
â”‚   â”œâ”€â”€ nginx/
â”‚   â”‚   â””â”€â”€ ragflow.conf          # Config Nginx
â”‚   â””â”€â”€ ragflow-logs/             # Logs des tÃ¢ches
â””â”€â”€ README.md                     # Cette documentation
\`\`\`

### docker-compose-gpu.yml

Services inclus :
- \`ragflow\` : Serveur principal RAGFlow
- \`mysql\` : Base de donnÃ©es
- \`redis\` : Cache et file de tÃ¢ches
- \`es01\` : Elasticsearch (indexation)
- \`minio\` : Stockage S3
- \`sglang-qwen3\` : LLM de chat (Qwen3-8B)
- \`ollama-bge-m3\` : ModÃ¨le d'embedding

---

## ğŸ“¦ Services

### RAGFlow Server
- **Ports** : 80 (HTTP), 443 (HTTPS via Nginx interne)
- **Image** : \`infiniflow/ragflow:latest-slim\`
- **GPU** : ActivÃ©
- **Restart** : \`unless-stopped\`

### SGLang (Chat LLM)
- **Port** : 30000
- **ModÃ¨le** : \`Qwen/Qwen3-8B\`
- **VRAM** : ~16GB
- **URL interne** : \`http://sglang-qwen3:30000/v1\`

### Ollama (Embedding)
- **Port** : 11434
- **ModÃ¨le** : \`bge-m3\`
- **VRAM** : ~2GB
- **URL interne** : \`http://ollama-bge-m3:11434\`

### MySQL
- **Port** : 5455
- **User** : \`root\`
- **Password** : \`infini_rag_flow\` (voir \`.env\`)
- **Database** : \`rag_flow\`

### Redis
- **Port** : 6379
- **Password** : \`infini_rag_flow\` (voir \`.env\`)

### Elasticsearch
- **Port** : 1200
- **Version** : 8.11.3
- **Index** : Chunks et documents

### MinIO (S3)
- **Console** : 9001
- **API** : 9000
- **Access Key** : voir \`.env\`

---

## ğŸ¤– ModÃ¨les utilisÃ©s

### 1. **Qwen3-8B** (Chat LLM)
- **Provider** : Alibaba Cloud (Qwen Team)
- **Taille** : 8 milliards de paramÃ¨tres
- **Langue** : Multilingue (excellent en franÃ§ais)
- **Use case** : GÃ©nÃ©ration de rÃ©ponses RAG
- **VRAM** : ~16GB
- **Format** : FP16

### 2. **bge-m3** (Embedding)
- **Provider** : BAAI (Beijing Academy of AI)
- **Dimensions** : 1024
- **Langue** : Multilingue (128 langues)
- **Use case** : Vectorisation de documents
- **VRAM** : ~2GB
- **Max tokens** : 8192

---

## ğŸ› ï¸ Commandes utiles

### Gestion des services

\`\`\`bash
# DÃ©marrer tous les services
docker compose -f docker-compose-gpu.yml up -d

# ArrÃªter tous les services
docker compose -f docker-compose-gpu.yml down

# RedÃ©marrer RAGFlow uniquement
docker compose -f docker-compose-gpu.yml restart ragflow

# Voir les logs
docker compose -f docker-compose-gpu.yml logs -f ragflow

# Voir l'utilisation GPU
watch -n 1 nvidia-smi
\`\`\`

### Gestion des modÃ¨les

\`\`\`bash
# TÃ©lÃ©charger un nouveau modÃ¨le dans Ollama
docker exec ollama-bge-m3 ollama pull <model-name>

# Lister les modÃ¨les Ollama
docker exec ollama-bge-m3 ollama list

# Tester SGLang
curl -X POST http://localhost:30000/v1/chat/completions \\
  -H "Content-Type: application/json" \\
  -d '{
    "model": "Qwen/Qwen3-8B",
    "messages": [{"role": "user", "content": "Bonjour!"}]
  }'
\`\`\`

### Debugging

\`\`\`bash
# Entrer dans le container RAGFlow
docker exec -it ragflow-server bash

# VÃ©rifier Redis (arrÃªter le parsing bloquÃ©)
docker exec ragflow-redis redis-cli -a infini_rag_flow FLUSHALL

# VÃ©rifier MySQL
docker exec -it ragflow-mysql mysql -uroot -pinfini_rag_flow rag_flow

# VÃ©rifier Elasticsearch
curl -X GET "http://localhost:1200/_cat/indices?v"
\`\`\`

### Maintenance

\`\`\`bash
# Nettoyer les logs
rm -rf /root/flowkura-infrastructure/ragflow/docker/ragflow-logs/*

# Backup de la base de donnÃ©es
docker exec ragflow-mysql mysqldump -uroot -pinfini_rag_flow rag_flow > backup.sql

# Restaurer la base
docker exec -i ragflow-mysql mysql -uroot -pinfini_rag_flow rag_flow < backup.sql
\`\`\`

---

## ï¿½ï¿½ Troubleshooting

### ProblÃ¨me : Parsing bloquÃ©

**Solution :**
\`\`\`bash
# Flusher Redis
docker exec ragflow-redis redis-cli -a infini_rag_flow FLUSHALL

# RedÃ©marrer RAGFlow
docker compose -f docker-compose-gpu.yml restart ragflow
\`\`\`

### ProblÃ¨me : Out of Memory (GPU)

**Solutions :**
1. Utiliser un modÃ¨le plus petit : \`Qwen3-4B\` au lieu de \`Qwen3-8B\`
2. Activer le chunked prefill dans SGLang
3. RÃ©duire \`max_total_tokens\` dans SGLang

### ProblÃ¨me : Connexion refusÃ©e aux modÃ¨les

**VÃ©rifier :**
\`\`\`bash
# SGLang est accessible ?
curl http://localhost:30000/health

# Ollama est accessible ?
curl http://localhost:11434/api/version

# Les containers sont sur le mÃªme rÃ©seau ?
docker network inspect ragflow_ragflow
\`\`\`

### ProblÃ¨me : SSL/HTTPS ne fonctionne pas

**VÃ©rifier :**
1. Le domaine pointe bien vers le serveur
2. Les ports 80/443 sont ouverts
3. Les certificats Let's Encrypt sont dans \`/root/flowkura-infrastructure/ragflow/docker/nginx/ssl/\`

---

## âš¡ Optimisations

### 1. Base de donnÃ©es (dÃ©jÃ  appliquÃ©es)

**MySQL** :
\`\`\`ini
innodb_buffer_pool_size = 4G
innodb_log_file_size = 512M
max_connections = 500
\`\`\`

**Redis** :
\`\`\`ini
maxmemory = 4gb
maxmemory-policy = allkeys-lru
\`\`\`

### 2. Parsing plus rapide

**Chunking optimisÃ©** :
- \`chunk_token_num\` : 512 (bon Ã©quilibre)
- \`task_page_size\` : 12 (parallÃ©lisme PDF)
- \`layout_recognize\` : DeepDOC (prÃ©cis)

**Parser par type de document** :
- PDF : \`naive\` ou \`paper\`
- Markdown : \`naive\`
- Excel : Activer \`html4excel\`

### 3. RequÃªtes RAG optimisÃ©es

**ParamÃ¨tres recommandÃ©s** :
\`\`\`json
{
  "similarity_threshold": 0.2,
  "vector_similarity_weight": 0.3,
  "top_n": 6,
  "top_k": 1024
}
\`\`\`

---

## ğŸ“š Ressources

- [RAGFlow Documentation](https://ragflow.io/docs)
- [SGLang Documentation](https://sgl-project.github.io/)
- [Ollama Models](https://ollama.com/library)
- [Qwen3 Model Card](https://huggingface.co/Qwen/Qwen3-8B)
- [BGE-M3 Model Card](https://huggingface.co/BAAI/bge-m3)

---

## ğŸ¤ Support

Pour toute question ou problÃ¨me :
1. VÃ©rifier les logs : \`docker compose logs -f\`
2. Consulter cette documentation
3. Contacter l'Ã©quipe Flowkura

---

## ğŸ“ Licence

PropriÃ©tÃ© de **Flowkura** - Tous droits rÃ©servÃ©s.

---

**DerniÃ¨re mise Ã  jour** : 19 novembre 2025
