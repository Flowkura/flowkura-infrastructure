version: '3.8'

services:
  # ===================================
  # RAGFlow - Core Service
  # ===================================
  ragflow:
    image: infiniflow/ragflow:v0.15.0
    container_name: ragflow-server
    restart: unless-stopped
    ports:
      - "9380:9380"
      - "80:80"
      - "443:443"
    networks:
      - ragflow-network
    volumes:
      - ./ragflow/volumes/ragflow:/ragflow
      - ./ragflow/volumes/nginx/ragflow.conf:/etc/nginx/conf.d/ragflow.conf
      - ./ragflow/volumes/nginx/proxy.conf:/etc/nginx/proxy.conf
      - ./ragflow/volumes/nginx/nginx.conf:/etc/nginx/nginx.conf
    environment:
      - CPUONLY=${CPUONLY:-0}
      - HF_ENDPOINT=https://huggingface.co
      - MAXTOKENS=${MAXTOKENS:-8192}
      - GITHUB_TOKEN=${GITHUB_TOKEN:-}
      - OPENAI_API_KEY=${OPENAI_API_KEY:-}
      - HUGGING_FACE_HUB_TOKEN=${HF_TOKEN}
      - WS_ORIGINS=${WS_ORIGINS:-*}
      - REGISTER_STATUS=${REGISTER_STATUS:-disabled}
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]

  # ===================================
  # Ollama - Embedding Model (BGE-M3)
  # ===================================
  ollama:
    image: ollama/ollama:latest
    container_name: ollama
    restart: unless-stopped
    ports:
      - "11434:11434"
    networks:
      - ragflow-network
    volumes:
      - ./ollama:/root/.ollama
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]

  # ===================================
  # SGLang - LLM Server (Qwen3-8B)
  # ===================================
  sglang:
    image: lmsysorg/sglang:latest
    container_name: sglang-qwen3
    restart: unless-stopped
    ports:
      - "8000:8000"
    networks:
      - ragflow-network
    volumes:
      - ~/.cache/huggingface:/root/.cache/huggingface
    environment:
      - HF_TOKEN=${HF_TOKEN}
    command: >
      python3 -m sglang.launch_server
      --model-path Qwen/Qwen3-8B
      --host 0.0.0.0
      --port 8000
      --served-model-name Qwen3-8B
      --trust-remote-code
      --mem-fraction-static 0.85
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]

networks:
  ragflow-network:
    driver: bridge
