# The RAGFlow team do not actively maintain docker-compose-gpu.yml, so use them at your own risk. 
# Pull requests to improve it are welcome.
include:
  - ./docker-compose-base.yml

services:
  ragflow:
    depends_on:
      mysql:
        condition: service_healthy
    image: ${RAGFLOW_IMAGE}
    container_name: ragflow-server
    ports:
      - 9380:9380
      - 8081:80
    volumes:
      - ./ragflow-logs:/ragflow/logs
      - ./nginx/ragflow.conf:/etc/nginx/conf.d/ragflow.conf
      - ./nginx/proxy.conf:/etc/nginx/proxy.conf
      - ./nginx/nginx.conf:/etc/nginx/nginx.conf
    env_file: .env
    environment:
      - TZ=${TIMEZONE}
      - HF_ENDPOINT=${HF_ENDPOINT}
      - MACOS=${MACOS}
    networks:
      - ragflow
    restart: on-failure
    extra_hosts:
      - "host.docker.internal:host-gateway"
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]

  # SGLang - Qwen3-8B (LLM)
  sglang-qwen3:
    image: lmsysorg/sglang:latest
    container_name: flowkura-sglang-qwen3
    command: >
      python3 -m sglang.launch_server
      --model Qwen/Qwen3-8B
      --host 0.0.0.0
      --port 30000
      --tp 1
      --mem-fraction-static 0.7
    volumes:
      - ~/.cache/huggingface:/root/.cache/huggingface
    environment:
      - CUDA_VISIBLE_DEVICES=0
      - HF_TOKEN=${HF_TOKEN}
    ports:
      - "30000:30000"
    networks:
      - ragflow
    restart: unless-stopped
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              device_ids: ['0']
              capabilities: [gpu]

  # SGLang - BGE-M3 (Embedding)
  sglang-embedding:
    image: lmsysorg/sglang:latest
    container_name: flowkura-sglang-embedding
    command: >
      python3 -m sglang.launch_server
      --model BAAI/bge-m3
      --host 0.0.0.0
      --port 30001
      --tp 1
      --mem-fraction-static 0.3
      --is-embedding
    volumes:
      - ~/.cache/huggingface:/root/.cache/huggingface
    environment:
      - CUDA_VISIBLE_DEVICES=0
      - HF_TOKEN=${HF_TOKEN}
    ports:
      - "30001:30001"
    networks:
      - ragflow
    restart: unless-stopped
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              device_ids: ['0']
              capabilities: [gpu]
