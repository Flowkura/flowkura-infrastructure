version: "3"

networks:
  ragflow:
    external: true

services:
  sglang-qwen3:
    image: lmsysorg/sglang:latest
    container_name: flowkura-sglang-qwen3
    restart: unless-stopped
    networks:
      - ragflow
    ports:
      - "8000:30000"
    volumes:
      - ~/.cache/huggingface:/root/.cache/huggingface
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    ipc: host
    command: |
      python3 -m sglang.launch_server \
        --model-path Qwen/Qwen3-8B \
        --port 30000 \
        --host 0.0.0.0

  ollama:
    image: ollama/ollama
    container_name: flowkura-ollama
    restart: unless-stopped
    networks:
      - ragflow
    ports:
      - "11434:11434"
    volumes:
      - ollama_data:/root/.ollama
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]

volumes:
  ollama_data:
    name: ollama_data
